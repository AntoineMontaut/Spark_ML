{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf metastore_db/*.lck\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlc = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "- Load the train and test sets\n",
    "- Check the schema, the variables have their right types?\n",
    "- If not, how to correctly load the datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "customSchema = StructType([StructField(\"PassengerId\", IntegerType(), True),\n",
    "                           StructField(\"Survived\", DoubleType(), True),\n",
    "                           StructField(\"Pclass\", IntegerType(), True), \n",
    "                           StructField(\"Name\", StringType(), True),\n",
    "                           StructField(\"Sex\", StringType(), True),\n",
    "                           StructField(\"Age\", DoubleType(), True),\n",
    "                           StructField(\"SibSp\", IntegerType(), True),\n",
    "                           StructField(\"Parch\", IntegerType(), True),\n",
    "                           StructField(\"Ticket\", StringType(), True),\n",
    "                           StructField(\"Fare\", DoubleType(), True),\n",
    "                           StructField(\"Cabin\", StringType(), True),\n",
    "                           StructField(\"Embarked\", StringType(), True)])\n",
    "\n",
    "customSchema2 = StructType([StructField(\"PassengerId\", IntegerType(), True),\n",
    "                           StructField(\"Pclass\", IntegerType(), True), \n",
    "                           StructField(\"Name\", StringType(), True),\n",
    "                           StructField(\"Sex\", StringType(), True),\n",
    "                           StructField(\"Age\", DoubleType(), True),\n",
    "                           StructField(\"SibSp\", IntegerType(), True),\n",
    "                           StructField(\"Parch\", IntegerType(), True),\n",
    "                           StructField(\"Ticket\", StringType(), True),\n",
    "                           StructField(\"Fare\", DoubleType(), True),\n",
    "                           StructField(\"Cabin\", StringType(), True),\n",
    "                           StructField(\"Embarked\", StringType(), True)])\n",
    "\n",
    "train = sqlc.read.csv(\"./train.csv\", header=True, schema=customSchema)\n",
    "test = sqlc.read.csv(\"./test.csv\", header=True, schema=customSchema2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sqlc.read.format('com.databricks.spark.csv')\\\n",
    "                .option('header', 'true')\\\n",
    "                .option('inferschema', 'true')\\\n",
    "                .option('mode', 'DROPMALFORMED')\\\n",
    "                .load('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for schema in titanic.schema:\n",
    "#     print(schema)\n",
    "    \n",
    "titanic.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "- Explore the features of your dataset\n",
    "- You can use DataFrame's ***describe*** method to get summary statistics\n",
    "    - hint: ***toPandas*** may be useful to ease the manipulation of small dataframes\n",
    "- Are there any ***NaN*** values in your dataset?\n",
    "- If so, define value/values to fill these ***NaN*** values\n",
    "    - hint: ***na*** property of DataFrames provide several methods of handling NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               PassengerId             Survived              Pclass  \\\n",
      "summary                                                               \n",
      "count                  891                  891                 891   \n",
      "mean                 446.0   0.3838383838383838   2.308641975308642   \n",
      "stddev   257.3538420152301  0.48659245426485753  0.8360712409770491   \n",
      "min                      1                  0.0                   1   \n",
      "max                    891                  1.0                   3   \n",
      "\n",
      "                                                     Name     Sex  \\\n",
      "summary                                                             \n",
      "count                                                 891     891   \n",
      "mean                                                 None    None   \n",
      "stddev                                               None    None   \n",
      "min      \"Andersson, Mr. August Edvard (\"\"Wennerstrom\"\")\"  female   \n",
      "max                           van Melkebeke, Mr. Philemon    male   \n",
      "\n",
      "                        Age               SibSp                Parch  \\\n",
      "summary                                                                \n",
      "count                   714                 891                  891   \n",
      "mean      29.69911764705882  0.5230078563411896  0.38159371492704824   \n",
      "stddev   14.526497332334035  1.1027434322934315   0.8060572211299488   \n",
      "min                    0.42                   0                    0   \n",
      "max                    80.0                   8                    6   \n",
      "\n",
      "                     Ticket               Fare Cabin Embarked  \n",
      "summary                                                        \n",
      "count                   891                891   204      889  \n",
      "mean     260318.54916792738   32.2042079685746  None     None  \n",
      "stddev   471609.26868834975  49.69342859718089  None     None  \n",
      "min                  110152                0.0   A10        C  \n",
      "max               WE/P 5735           512.3292     T        S  \n",
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|   77|\n",
      "|    null|    2|\n",
      "|       C|  168|\n",
      "|       S|  644|\n",
      "+--------+-----+\n",
      "\n",
      "None\n",
      "{'Parch': 0.08162940708348339, 'Fare': 0.2573065223849626, 'Age': 0.010539215871285682, 'Pclass': -0.3384810359610151, 'SibSp': -0.0353224988857356}\n",
      "{'Parch': 0, 'Sex': 0, 'Name': 0, 'Pclass': 0, 'SibSp': 0, 'Survived': 0, 'Fare': 0, 'Ticket': 0, 'Age': 177, 'Embarked': 2, 'PassengerId': 0, 'Cabin': 687}\n",
      "29.69911764705882\n",
      "+------+------+------------------+\n",
      "|   Sex|PClass|          avg(age)|\n",
      "+------+------+------------------+\n",
      "|  male|     3|26.507588932806325|\n",
      "|female|     3|             21.75|\n",
      "|female|     1| 34.61176470588235|\n",
      "|female|     2|28.722972972972972|\n",
      "|  male|     2| 30.74070707070707|\n",
      "|  male|     1| 41.28138613861386|\n",
      "+------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating summary statistics and turning it into Pandas DF\n",
    "train_desc = train.describe().toPandas().set_index('summary')\n",
    "print(train_desc)\n",
    "\n",
    "print(train.groupBy('Embarked').count().show())\n",
    "\n",
    "# Computing correlations between Survived and some features\n",
    "print({col:train.stat.corr('Survived',col) for col in ['Pclass','Age','SibSp','Parch','Fare']})\n",
    "\n",
    "# Checking which columns have NULL values\n",
    "print({col:train.where(train[col].isNull()).count() for col in train.columns})\n",
    "\n",
    "# Taking the mean age from the Pandas DF\n",
    "ageMean = float(train_desc.loc['mean']['Age'])\n",
    "fareMean = float(train_desc.loc['mean']['Fare'])\n",
    "print(ageMean)\n",
    "\n",
    "# Filling the Age in both train and test datasets\n",
    "trainFilled = train.na.fill({'Age': ageMean, 'Embarked': 'S'})\n",
    "testFilled = test.na.fill({'Age': ageMean, 'Embarked': 'S', 'Fare': fareMean})\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "train.groupby('Sex','PClass').agg(F.mean('age')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.0</td>\n",
       "      <td>0.3838383838383838</td>\n",
       "      <td>2.308641975308642</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>29.69911764705882</td>\n",
       "      <td>0.5230078563411896</td>\n",
       "      <td>0.38159371492704824</td>\n",
       "      <td>260318.54916792738</td>\n",
       "      <td>32.2042079685746</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stddev</th>\n",
       "      <td>257.3538420152301</td>\n",
       "      <td>0.48659245426485753</td>\n",
       "      <td>0.8360712409770491</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>14.526497332334035</td>\n",
       "      <td>1.1027434322934315</td>\n",
       "      <td>0.8060572211299488</td>\n",
       "      <td>471609.26868834975</td>\n",
       "      <td>49.69342859718089</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Andersson, Mr. August Edvard (\"\"Wennerstrom\"\")\"</td>\n",
       "      <td>female</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A10</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>van Melkebeke, Mr. Philemon</td>\n",
       "      <td>male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>WE/P 5735</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>T</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PassengerId             Survived              Pclass  \\\n",
       "summary                                                               \n",
       "count                  891                  891                 891   \n",
       "mean                 446.0   0.3838383838383838   2.308641975308642   \n",
       "stddev   257.3538420152301  0.48659245426485753  0.8360712409770491   \n",
       "min                      1                    0                   1   \n",
       "max                    891                    1                   3   \n",
       "\n",
       "                                                     Name     Sex  \\\n",
       "summary                                                             \n",
       "count                                                 891     891   \n",
       "mean                                                 None    None   \n",
       "stddev                                               None    None   \n",
       "min      \"Andersson, Mr. August Edvard (\"\"Wennerstrom\"\")\"  female   \n",
       "max                           van Melkebeke, Mr. Philemon    male   \n",
       "\n",
       "                        Age               SibSp                Parch  \\\n",
       "summary                                                                \n",
       "count                   714                 891                  891   \n",
       "mean      29.69911764705882  0.5230078563411896  0.38159371492704824   \n",
       "stddev   14.526497332334035  1.1027434322934315   0.8060572211299488   \n",
       "min                    0.42                   0                    0   \n",
       "max                    80.0                   8                    6   \n",
       "\n",
       "                     Ticket               Fare Cabin Embarked  \n",
       "summary                                                        \n",
       "count                   891                891   204      889  \n",
       "mean     260318.54916792738   32.2042079685746  None     None  \n",
       "stddev   471609.26868834975  49.69342859718089  None     None  \n",
       "min                  110152                0.0   A10        C  \n",
       "max               WE/P 5735           512.3292     T        S  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.describe().toPandas().set_index('summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = train.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Duran y More, Miss. Asuncion</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId    Survived      Pclass                          Name  \\\n",
       "count    891.000000  891.000000  891.000000                           891   \n",
       "unique          NaN         NaN         NaN                           891   \n",
       "top             NaN         NaN         NaN  Duran y More, Miss. Asuncion   \n",
       "freq            NaN         NaN         NaN                             1   \n",
       "mean     446.000000    0.383838    2.308642                           NaN   \n",
       "std      257.353842    0.486592    0.836071                           NaN   \n",
       "min        1.000000    0.000000    1.000000                           NaN   \n",
       "25%      223.500000    0.000000    2.000000                           NaN   \n",
       "50%      446.000000    0.000000    3.000000                           NaN   \n",
       "75%      668.500000    1.000000    3.000000                           NaN   \n",
       "max      891.000000    1.000000    3.000000                           NaN   \n",
       "\n",
       "         Sex         Age       SibSp       Parch Ticket        Fare Cabin  \\\n",
       "count    891  714.000000  891.000000  891.000000    891  891.000000   204   \n",
       "unique     2         NaN         NaN         NaN    681         NaN   147   \n",
       "top     male         NaN         NaN         NaN   1601         NaN    G6   \n",
       "freq     577         NaN         NaN         NaN      7         NaN     4   \n",
       "mean     NaN   29.699118    0.523008    0.381594    NaN   32.204208   NaN   \n",
       "std      NaN   14.526497    1.102743    0.806057    NaN   49.693429   NaN   \n",
       "min      NaN    0.420000    0.000000    0.000000    NaN    0.000000   NaN   \n",
       "25%      NaN   20.125000    0.000000    0.000000    NaN    7.910400   NaN   \n",
       "50%      NaN   28.000000    0.000000    0.000000    NaN   14.454200   NaN   \n",
       "75%      NaN   38.000000    1.000000    0.000000    NaN   31.000000   NaN   \n",
       "max      NaN   80.000000    8.000000    6.000000    NaN  512.329200   NaN   \n",
       "\n",
       "       Embarked  \n",
       "count       889  \n",
       "unique        3  \n",
       "top           S  \n",
       "freq        644  \n",
       "mean        NaN  \n",
       "std         NaN  \n",
       "min         NaN  \n",
       "25%         NaN  \n",
       "50%         NaN  \n",
       "75%         NaN  \n",
       "max         NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null float64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "1             2       1.0       1   \n",
       "3             4       1.0       1   \n",
       "6             7       0.0       1   \n",
       "10           11       1.0       3   \n",
       "11           12       1.0       1   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "\n",
       "    Parch    Ticket     Fare Cabin Embarked  \n",
       "1       0  PC 17599  71.2833   C85        C  \n",
       "3       0    113803  53.1000  C123        S  \n",
       "6       0     17463  51.8625   E46        S  \n",
       "10      1   PP 9549  16.7000    G6        S  \n",
       "11      0    113783  26.5500  C103        S  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[~df['Cabin'].isnull(), :].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "- How to handle categorical features?\n",
    "    - hint: check the Estimators and Transformers\n",
    "- Assemble all desired features into a Vector using the VectorAssembler Transformer\n",
    "- Make sure to end up with a DataFrame with two columns: ***Survived*** and ***vFeatures***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "for (IN, OUT) in [('Sex', 'Nsex'), ('Embarked', 'Nembarked')]:\n",
    "    indexer = StringIndexer().setInputCol(IN).setOutputCol(OUT)#.setHandleInvalid('skip') would have been better\n",
    "    trainFilled = indexer.fit(trainFilled).transform(trainFilled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder().setInputCol('Nembarked').setOutputCol('HotEmbarked')\n",
    "trainFilled = encoder.transform(trainFilled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----+---------+-------------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Nsex|Nembarked|  HotEmbarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----+---------+-------------+\n",
      "|          1|     0.0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S| 0.0|      0.0|(2,[0],[1.0])|\n",
      "|          2|     1.0|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C| 1.0|      1.0|(2,[1],[1.0])|\n",
      "|          3|     1.0|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S| 1.0|      0.0|(2,[0],[1.0])|\n",
      "|          4|     1.0|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S| 1.0|      0.0|(2,[0],[1.0])|\n",
      "|          5|     0.0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S| 0.0|      0.0|(2,[0],[1.0])|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainFilled.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler().setInputCols(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Nsex', 'HotEmbarked']).setOutputCol('features')\n",
    "df_train_features = assembler.transform(trainFilled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----+---------+-------------+--------------------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Nsex|Nembarked|  HotEmbarked|            features|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----+---------+-------------+--------------------+\n",
      "|          1|     0.0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S| 0.0|      0.0|(2,[0],[1.0])|[3.0,22.0,1.0,0.0...|\n",
      "|          2|     1.0|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C| 1.0|      1.0|(2,[1],[1.0])|[1.0,38.0,1.0,0.0...|\n",
      "|          3|     1.0|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S| 1.0|      0.0|(2,[0],[1.0])|[3.0,26.0,0.0,0.0...|\n",
      "|          4|     1.0|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S| 1.0|      0.0|(2,[0],[1.0])|[1.0,35.0,1.0,0.0...|\n",
      "|          5|     0.0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S| 0.0|      0.0|(2,[0],[1.0])|(8,[0,1,4,6],[3.0...|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----+---------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train_features.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+----+---------+-------------+--------------------+\n",
      "|PassengerId|Pclass|                Name|   Sex| Age|SibSp|Parch| Ticket|   Fare|Cabin|Embarked|Nsex|Nembarked|  HotEmbarked|            features|\n",
      "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+----+---------+-------------+--------------------+\n",
      "|        892|     3|    Kelly, Mr. James|  male|34.5|    0|    0| 330911| 7.8292| null|       Q| 0.0|      2.0|    (2,[],[])|(8,[0,1,4],[3.0,3...|\n",
      "|        893|     3|Wilkes, Mrs. Jame...|female|47.0|    1|    0| 363272|    7.0| null|       S| 1.0|      0.0|(2,[0],[1.0])|[3.0,47.0,1.0,0.0...|\n",
      "|        894|     2|Myles, Mr. Thomas...|  male|62.0|    0|    0| 240276| 9.6875| null|       Q| 0.0|      2.0|    (2,[],[])|(8,[0,1,4],[2.0,6...|\n",
      "|        895|     3|    Wirz, Mr. Albert|  male|27.0|    0|    0| 315154| 8.6625| null|       S| 0.0|      0.0|(2,[0],[1.0])|(8,[0,1,4,6],[3.0...|\n",
      "|        896|     3|Hirvonen, Mrs. Al...|female|22.0|    1|    1|3101298|12.2875| null|       S| 1.0|      0.0|(2,[0],[1.0])|[3.0,22.0,1.0,1.0...|\n",
      "+-----------+------+--------------------+------+----+-----+-----+-------+-------+-----+--------+----+---------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (IN, OUT) in [('Sex', 'Nsex'), ('Embarked', 'Nembarked')]:\n",
    "    indexer = StringIndexer().setInputCol(IN).setOutputCol(OUT)\n",
    "    testFilled = indexer.fit(testFilled).transform(testFilled)\n",
    "    \n",
    "encoder = OneHotEncoder().setInputCol('Nembarked').setOutputCol('HotEmbarked')\n",
    "testFilled = encoder.transform(testFilled)\n",
    "\n",
    "assembler = VectorAssembler().setInputCols(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Nsex', 'HotEmbarked']).setOutputCol('features')\n",
    "df_test_features = assembler.transform(testFilled)\n",
    "df_test_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "- Apply a normalization Estimator of your choice to the ***features*** vector obtained in Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().setInputCol('features').setOutputCol('scaled_feat').setWithStd(True).setWithMean(True)\n",
    "df_train_scaled = scaler.fit(df_train_features.select('survived', 'features')) \\\n",
    "                        .transform(df_train_features.select('survived', 'features'))\n",
    "    \n",
    "df_test_scaled = scaler.fit(df_test_features.select('features')) \\\n",
    "                        .transform(df_test_features.select('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|survived|            features|         scaled_feat|\n",
      "+--------+--------------------+--------------------+\n",
      "|     0.0|[3.0,22.0,1.0,0.0...|[0.82691281652436...|\n",
      "|     1.0|[1.0,38.0,1.0,0.0...|[-1.5652278312782...|\n",
      "|     1.0|[3.0,26.0,0.0,0.0...|[0.82691281652436...|\n",
      "|     1.0|[1.0,35.0,1.0,0.0...|[-1.5652278312782...|\n",
      "|     0.0|(8,[0,1,4,6],[3.0...|[0.82691281652436...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train_scaled.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 14 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            418 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           418 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "Nsex           418 non-null float64\n",
      "Nembarked      418 non-null float64\n",
      "HotEmbarked    418 non-null object\n",
      "dtypes: float64(4), int64(4), object(6)\n",
      "memory usage: 45.8+ KB\n"
     ]
    }
   ],
   "source": [
    "testFilled.toPandas().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            features|         scaled_feat|\n",
      "+--------------------+--------------------+\n",
      "|(8,[0,1,4],[3.0,3...|[0.87243644459912...|\n",
      "|[3.0,47.0,1.0,0.0...|[0.87243644459912...|\n",
      "|(8,[0,1,4],[2.0,6...|[-0.3154411900667...|\n",
      "|(8,[0,1,4,6],[3.0...|[0.87243644459912...|\n",
      "|[3.0,22.0,1.0,1.0...|[0.87243644459912...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test_scaled.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "- Instead of doing transformations on separate steps, put everything together with a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (IN, OUT) in [('Sex', 'Nsex'), ('Embarked', 'Nembarked')]:\n",
    "    indexer = StringIndexer().setInputCol(IN).setOutputCol(OUT)\n",
    "    testFilled = indexer.fit(testFilled).transform(testFilled)\n",
    "    \n",
    "encoder = OneHotEncoder().setInputCol('Nembarked').setOutputCol('HotEmbarked')\n",
    "testFilled = encoder.transform(testFilled)\n",
    "\n",
    "assembler = VectorAssembler().setInputCols(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Nsex', 'HotEmbarked']).setOutputCol('features')\n",
    "df_train_features = assembler.transform(trainFilled)\n",
    "\n",
    "assembler = VectorAssembler().setInputCols(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Nsex', 'HotEmbarked']).setOutputCol('features')\n",
    "df_test_features = assembler.transform(testFilled)\n",
    "df_test_features.show(5)\n",
    "\n",
    "scaler = StandardScaler().setInputCol('features').setOutputCol('scaled_feat').setWithStd(True).setWithMean(True)\n",
    "df_train_scaled = scaler.fit(df_train_features.select('survived', 'features')) \\\n",
    "                        .transform(df_train_features.select('survived', 'features'))\n",
    "    \n",
    "df_test_scaled = scaler.fit(df_test_features.select('features')) \\\n",
    "                        .transform(df_test_features.select('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import Pipeline\n",
    "\n",
    "indexer1 = StringIndexer().setInputCol('Sex').setOutputCol('Nsex')\n",
    "indexer2 = StringIndexer().setInputCol('Embarked').setOutputCol('Nembarked')\n",
    "    \n",
    "encoder = OneHotEncoder().setInputCol('Nembarked').setOutputCol('HotEmbarked')\n",
    "\n",
    "assembler = VectorAssembler().setInputCols(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Nsex', 'HotEmbarked']).setOutputCol('features')\n",
    "\n",
    "scaler = StandardScaler().setInputCol('features').setOutputCol('scaled_feat').setWithStd(True).setWithMean(True)\n",
    "\n",
    "pipeline = Pipeline().setStages([indexer1, indexer2, encoder, assembler, scaler])\n",
    "\n",
    "preprocessing_model = pipeline.fit(trainFilled)\n",
    "preprocessed_train = preprocessing_model.transform(trainFilled)\n",
    "preprocessed_test = preprocessing_model.transform(testFilled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----+---------+-------------+--------------------+--------------------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Nsex|Nembarked|  HotEmbarked|            features|         scaled_feat|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----+---------+-------------+--------------------+--------------------+\n",
      "|          1|     0.0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S| 0.0|      0.0|(2,[0],[1.0])|[3.0,22.0,1.0,0.0...|[0.82691281652436...|\n",
      "|          2|     1.0|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C| 1.0|      1.0|(2,[1],[1.0])|[1.0,38.0,1.0,0.0...|[-1.5652278312782...|\n",
      "|          3|     1.0|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S| 1.0|      0.0|(2,[0],[1.0])|[3.0,26.0,0.0,0.0...|[0.82691281652436...|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+----+---------+-------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-----------+------+--------------------+------+----+-----+-----+------+------+-----+--------+----+---------+-------------+--------------------+--------------------+\n",
      "|PassengerId|Pclass|                Name|   Sex| Age|SibSp|Parch|Ticket|  Fare|Cabin|Embarked|Nsex|Nembarked|  HotEmbarked|            features|         scaled_feat|\n",
      "+-----------+------+--------------------+------+----+-----+-----+------+------+-----+--------+----+---------+-------------+--------------------+--------------------+\n",
      "|        892|     3|    Kelly, Mr. James|  male|34.5|    0|    0|330911|7.8292| null|       Q| 0.0|      2.0|    (2,[],[])|(8,[0,1,4],[3.0,3...|[0.82691281652436...|\n",
      "|        893|     3|Wilkes, Mrs. Jame...|female|47.0|    1|    0|363272|   7.0| null|       S| 1.0|      0.0|(2,[0],[1.0])|[3.0,47.0,1.0,0.0...|[0.82691281652436...|\n",
      "|        894|     2|Myles, Mr. Thomas...|  male|62.0|    0|    0|240276|9.6875| null|       Q| 0.0|      2.0|    (2,[],[])|(8,[0,1,4],[2.0,6...|[-0.3691575073769...|\n",
      "+-----------+------+--------------------+------+----+-----+-----+------+------+-----+--------+----+---------+-------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------+--------------------+\n",
      "|Survived|         scaled_feat|\n",
      "+--------+--------------------+\n",
      "|     0.0|[0.82691281652436...|\n",
      "|     1.0|[-1.5652278312782...|\n",
      "|     1.0|[0.82691281652436...|\n",
      "+--------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+\n",
      "|         scaled_feat|\n",
      "+--------------------+\n",
      "|[0.82691281652436...|\n",
      "|[0.82691281652436...|\n",
      "|[-0.3691575073769...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessed_train.show(3)\n",
    "preprocessed_test.show(3)\n",
    "\n",
    "subset_train = preprocessed_train.select('Survived', 'scaled_feat')\n",
    "subset_test = preprocessed_test.select('scaled_feat')\n",
    "\n",
    "subset_train.show(3)\n",
    "subset_test.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6\n",
    "- Train a classifier of your choice (for instance, Random Forest) using your dataset of LabeledPoints\n",
    "- Make predictions for the training data\n",
    "- Use the evaluators to find the Area Under ROC and Accuracy of your model\n",
    "- How is your model performing? Try to tune its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "rfc = RandomForestClassifier().setLabelCol('Survived').setFeaturesCol('scaled_feat') \\\n",
    "                            .setNumTrees(13).setMaxDepth(7)\n",
    "model_rfc = rfc.fit(subset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(8, {0: 0.149, 1: 0.1326, 2: 0.0442, 3: 0.0465, 4: 0.1742, 5: 0.4025, 6: 0.0193, 7: 0.0318})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rfc.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+----------+\n",
      "|Survived|         scaled_feat|       rawPrediction|         probability|prediction|\n",
      "+--------+--------------------+--------------------+--------------------+----------+\n",
      "|     0.0|[0.82691281652436...|[11.6144769351195...|[0.89342130270150...|       0.0|\n",
      "|     1.0|[-1.5652278312782...|[0.41176470588235...|[0.03167420814479...|       1.0|\n",
      "|     1.0|[0.82691281652436...|[5.40697527641242...|[0.41592117510864...|       1.0|\n",
      "+--------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subset_trained = model_rfc.transform(subset_train)\n",
    "subset_trained.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8672227015626498 0.8866442199775533\n"
     ]
    }
   ],
   "source": [
    "evaluator_roc = BinaryClassificationEvaluator().setLabelCol('Survived')\\\n",
    "    .setRawPredictionCol('prediction').setMetricName('areaUnderROC')\n",
    "\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator().setLabelCol('Survived')\\\n",
    "    .setPredictionCol('prediction').setMetricName('accuracy')\n",
    "    \n",
    "roc = evaluator_roc.evaluate(subset_trained)\n",
    "accuracy = evaluator_accuracy.evaluate(subset_trained)\n",
    "print(roc, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7\n",
    "- Take a look at the test data - use DataFrame's ***createOrReplaceTempView*** method to perform SQL queries over the data\n",
    "    - hint: check if there are any NULL values in the dataset - if so, handle them\n",
    "- Apply the transformations to the test data\n",
    "    - hint: include the model to the pipeline\n",
    "- Make predictions using the model previously trained and the transformed test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8\n",
    "\n",
    "- Load the answers for the ***test*** data\n",
    "- Combine it with your predictions into a single DataFrame\n",
    "- Use the evaluator you created on ***Step 6***\n",
    "- What was your score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
